{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 173315: expected 18 fields, saw 20\\n'\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_user = pd.read_csv('data/table1_user',encoding='utf-8',index_col = False, delimiter='\\t',\n",
    "                                 )\n",
    "train_user['cur_jd_type'] = train_user['cur_jd_type'].astype(str)\n",
    "train_user.loc[train_user['cur_jd_type']=='nan',['cur_jd_type']] = '无业'\n",
    "train_job = pd.read_csv(\"data/table2_jd\",delimiter=\"\\t\",error_bad_lines=False)\n",
    "train_action = pd.read_csv(\"data/table3_action\",delimiter=\"\\t\")\n",
    "test_action = pd.read_csv(\"data/zhaopin_round1_user_exposure_B_20190819\",delim_whitespace=True)\n",
    "test_user = pd.read_csv(\"data/user_ToBePredicted\",delimiter=\"\\t\")\n",
    "test_user['cur_jd_type'] = test_user['cur_jd_type'].astype(str)\n",
    "test_user.loc[test_user['cur_jd_type']=='nan',['cur_jd_type']] = '无业'\n",
    "train_action['mix_sat']  = train_action['satisfied']*10+train_action['delivered']*3\n",
    "train_action.loc[train_action.mix_sat==13,'mix_sat'] =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_table = pd.merge(train_action,train_user,how=\"inner\",on=\"user_id\")\n",
    "train_big_table = pd.merge(train_big_table,train_job,how=\"inner\",on=\"jd_no\")\n",
    "test_big_table = pd.merge(test_action,test_user,how=\"inner\",on=\"user_id\")\n",
    "test_big_table = pd.merge(test_big_table,train_job,how=\"inner\",on=\"jd_no\")\n",
    "train_big_table.drop_duplicates(inplace=True)\n",
    "test_big_table.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_table['statis_del'] = train_big_table['satisfied']\n",
    "train_big_table.loc[(train_big_table['statis_del']==0)&(train_big_table['delivered']==1),['statis_del']]=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_sub_series = train_big_table['jd_sub_type'].value_counts()\n",
    "train_big_table.loc[~train_big_table['jd_sub_type'].isin(jd_sub_series[jd_sub_series>30].index.tolist()),['jd_sub_type']]='小众'\n",
    "test_big_table.loc[~test_big_table['jd_sub_type'].isin(jd_sub_series[jd_sub_series>30].index.tolist()),['jd_sub_type']]='小众'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jd_title_series = train_big_table['jd_title'].value_counts()\n",
    "train_big_table.loc[~train_big_table['jd_title'].isin(jd_title_series[jd_title_series>30].index.tolist()),['jd_title']]='小众'\n",
    "test_big_table.loc[~test_big_table['jd_title'].isin(jd_title_series[jd_title_series>30].index.tolist()),['jd_title']]='小众'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desire_jd_type_id_series = train_big_table['desire_jd_type_id'].value_counts()\n",
    "train_big_table.loc[~train_big_table['desire_jd_type_id'].isin(desire_jd_type_id_series[desire_jd_type_id_series>30].index.tolist()),['desire_jd_type_id']]='小众'\n",
    "test_big_table.loc[~test_big_table['desire_jd_type_id'].isin(desire_jd_type_id_series[desire_jd_type_id_series>30].index.tolist()),['desire_jd_type_id']]='小众'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_jd_industry_series = train_big_table['desire_jd_industry_id'].value_counts()\n",
    "train_big_table.loc[~train_big_table['desire_jd_industry_id'].isin(desire_jd_industry_series[desire_jd_industry_series>30].index.tolist()),['desire_jd_industry_id']]='小众'\n",
    "test_big_table.loc[~test_big_table['desire_jd_industry_id'].isin(desire_jd_industry_series[desire_jd_industry_series>30].index.tolist()),['desire_jd_industry_id']]='小众'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_jd_action_series = train_big_table.groupby(['cur_jd_type'])['browsed'].count()\n",
    "cur_jd_action =pd.DataFrame({'cur_jd_type':cur_jd_action_series.index, 'cur_jd_pos_cont':cur_jd_action_series.values})\n",
    "cur_jd_action['cur_jd_statis_del_rate'] = train_big_table.groupby(['cur_jd_type'])['statis_del'].mean().values\n",
    "test_big_table = pd.merge(test_big_table,cur_jd_action,how=\"left\",on=\"cur_jd_type\")\n",
    "test_big_table.loc[test_big_table['cur_jd_pos_cont'].isnull(),['cur_jd_statis_del_rate']]=cur_jd_action[cur_jd_action['cur_jd_type'].str.contains('其他')][['cur_jd_statis_del_rate']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_sub_action_series = train_big_table.groupby(['jd_sub_type'])['browsed'].count()\n",
    "jd_sub_action =pd.DataFrame({'jd_sub_type':jd_sub_action_series.index, 'jd_sub_pos_cont':jd_sub_action_series.values})\n",
    "jd_sub_action['jd_sub_statis_del_rate'] = train_big_table.groupby(['jd_sub_type'])['statis_del'].mean().values\n",
    "test_big_table = pd.merge(test_big_table,jd_sub_action,how=\"left\",on=\"jd_sub_type\")\n",
    "test_big_table.loc[test_big_table['jd_sub_pos_cont'].isnull(),['jd_sub_statis_del_rate']] =jd_sub_action[jd_sub_action['jd_sub_type'].str.contains('小众')][['jd_sub_statis_del_rate']].values[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desire_jd_industry_action_series = train_big_table.groupby(['desire_jd_type_id'])['browsed'].count()\n",
    "desire_jd_industry_action =pd.DataFrame({'desire_jd_type_id':desire_jd_industry_action_series.index, 'desire_jd_industry_pos_cont':desire_jd_industry_action_series.values})\n",
    "desire_jd_industry_action['desire_jd_industry_statis_del_rate'] = train_big_table.groupby(['desire_jd_type_id'])['statis_del'].mean().values\n",
    "test_big_table = pd.merge(test_big_table,desire_jd_industry_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "test_big_table.loc[test_big_table['desire_jd_industry_pos_cont'].isnull(),['desire_jd_industry_statis_del_rate']]=desire_jd_industry_action[desire_jd_industry_action['desire_jd_type_id'].str.contains('小众')][['desire_jd_industry_statis_del_rate']].values[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "jd_title_series = train_big_table.groupby(['jd_title'])['browsed'].count()\n",
    "jd_title_action =pd.DataFrame({'jd_title':jd_title_series.index, 'cur_jd_pos_cont':jd_title_series.values})\n",
    "jd_title_action['jd_title_statis_del_rate'] = train_big_table.groupby(['jd_title'])['statis_del'].mean().values\n",
    "test_big_table = pd.merge(test_big_table,jd_title_action,how=\"left\",on=\"jd_title\")\n",
    "test_big_table.loc[test_big_table['jd_title'].isnull(),['jd_title_statis_del_rate']]=jd_title_action[jd_title_action['jd_title'].str.contains('小众')][['jd_title_statis_del_rate']].values[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndesire_jd_type_action_series = train_big_table.groupby([\\'desire_jd_type_id\\'])[\\'browsed\\'].count()\\ndesire_jd_type_action =pd.DataFrame({\\'desire_jd_type_id\\':desire_jd_type_action_series.index, \\'desire_jd_type_pos_cont\\':desire_jd_type_action_series.values})\\ndesire_jd_type_action[\\'desire_jd_type_statis_del_rate\\'] = train_big_table.groupby([\\'desire_jd_type_id\\'])[\\'statis_del\\'].mean().values\\ntest_big_table = pd.merge(test_big_table,desire_jd_type_action,how=\"left\",on=\"desire_jd_type_id\")\\ntest_big_table.loc[test_big_table[\\'desire_jd_type_pos_cont\\'].isnull(),[\\'desire_jd_type_statis_del_rate\\']] =desire_jd_type_action[desire_jd_type_action[\\'desire_jd_type_id\\'].str.contains(\\'小众\\')][[\\'desire_jd_type_statis_del_rate\\']].values[0]\\n'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "desire_jd_type_action_series = train_big_table.groupby(['desire_jd_type_id'])['browsed'].count()\n",
    "desire_jd_type_action =pd.DataFrame({'desire_jd_type_id':desire_jd_type_action_series.index, 'desire_jd_type_pos_cont':desire_jd_type_action_series.values})\n",
    "desire_jd_type_action['desire_jd_type_statis_del_rate'] = train_big_table.groupby(['desire_jd_type_id'])['statis_del'].mean().values\n",
    "test_big_table = pd.merge(test_big_table,desire_jd_type_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "test_big_table.loc[test_big_table['desire_jd_type_pos_cont'].isnull(),['desire_jd_type_statis_del_rate']] =desire_jd_type_action[desire_jd_type_action['desire_jd_type_id'].str.contains('小众')][['desire_jd_type_statis_del_rate']].values[0]\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_table['start_date'].fillna('na',inplace=True)\n",
    "test_big_table['start_date'].fillna('na',inplace=True)\n",
    "train_big_table['end_date'].fillna('na',inplace=True)\n",
    "test_big_table['end_date'].fillna('na',inplace=True)\n",
    "train_big_table['start_date'] = train_big_table['start_date'].astype(str)\n",
    "train_big_table['end_date'] = train_big_table['end_date'].astype(str)\n",
    "test_big_table['start_date'] = test_big_table['start_date'].astype(str)\n",
    "test_big_table['end_date'] = test_big_table['end_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def remain_date(x):\n",
    "    if  'N' in x :\n",
    "        return 99999;\n",
    "    elif 'na' in x:\n",
    "        return -1\n",
    "    else:\n",
    "        d1 = datetime.strptime('20190327', \"%Y%m%d\")\n",
    "        d2 = datetime.strptime(x, \"%Y%m%d\")\n",
    "        return abs((d2 - d1).days)\n",
    "    \n",
    "train_big_table['remain_date'] = train_big_table['end_date'].apply(remain_date)\n",
    "test_big_table['remain_date'] = test_big_table['end_date'].apply(remain_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_convert(x):\n",
    "    if  'N' in x:\n",
    "        return -1;\n",
    "    elif 'na' in x:\n",
    "        return -1\n",
    "    else:\n",
    "        if int(x[0:6])< 201804:\n",
    "            return '201804'\n",
    "        else:\n",
    "            return x[0:6]\n",
    "\n",
    "train_big_table['start_month'] = train_big_table['start_date'].apply(month_convert)\n",
    "test_big_table['start_month'] = test_big_table['start_date'].apply(month_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(citys,index):\n",
    "    city_list = citys.split(\",\")\n",
    "    if index < len(city_list):\n",
    "        city = city_list[index]\n",
    "        if city != \"-\":\n",
    "            city = int(city)\n",
    "        else:\n",
    "            city = -1\n",
    "    else:\n",
    "        city = -1\n",
    "    return city\n",
    "\n",
    "def exp_in_desc(exp,desc):\n",
    "    if str(exp) == \"nan\":\n",
    "        exp = \"\"\n",
    "    exps = exp.split(\"|\")\n",
    "    num = 0\n",
    "    for item in exps:\n",
    "        if item in desc:\n",
    "            num+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year_dict = {\n",
    "    305: 4,\n",
    "    -1:-1,\n",
    "    1:1,\n",
    "    103:2,\n",
    "    0:0,\n",
    "    510:7,\n",
    "    1099:10,\n",
    "    399:4,\n",
    "    599:7,\n",
    "    199:1,\n",
    "    299:2,\n",
    "    110:1\n",
    "}\n",
    "degree_dict = {\n",
    "    \"初中\":1,\n",
    "    \"中技\":2,\n",
    "    \"高中\":3,\n",
    "    \"中专\":3,\n",
    "    \"大专\":4,\n",
    "    \"本科\":5,\n",
    "    \"硕士\":6,\n",
    "    \"博士\":7,\n",
    "    \"EMBA\":7,\n",
    "    \"MBA\":6,\n",
    "    \"其他\":0,\n",
    "    \"请选择\":0,\n",
    "    \"\\\\N\":0,\n",
    "    \"na\":0\n",
    "}\n",
    "min_salary_dict = {\n",
    "    100002000:1000,\n",
    "    400106000:4001,\n",
    "    0:0,\n",
    "    200104000:2001,\n",
    "    600108000:6001,\n",
    "    800110000:8001,\n",
    "    1000115000:10001,\n",
    "    2500199999:25001,\n",
    "    1500125000:15001,\n",
    "    3500150000:35001,\n",
    "    70001100000:70001,\n",
    "    1000:0,\n",
    "    100001150000:100001,\n",
    "    2500135000:25001,\n",
    "    5000170000:50001\n",
    "}\n",
    "max_salary_dict = {\n",
    "    100002000:2000,\n",
    "    400106000:6000,\n",
    "    0:0,\n",
    "    200104000:4000,\n",
    "    600108000:8000,\n",
    "    800110000:10000,\n",
    "    1000115000:15000,\n",
    "    2500199999:99999,\n",
    "    1500125000:25000,\n",
    "    3500150000:50000,\n",
    "    70001100000:100000,\n",
    "    1000:1000,\n",
    "    100001150000:150000,\n",
    "    2500135000:35000,\n",
    "    5000170000:70000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def fe(df):\n",
    "    df[\"desire_jd_city_1\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=0))\n",
    "    df[\"desire_jd_city_2\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=1))\n",
    "    df[\"desire_jd_city_3\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=2))\n",
    "    df[\"desire_jd_city_num\"] = df[[\"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\"]].sum(axis=1)\n",
    "    \n",
    "    df[\"city_equal_desired_city_1\"] = df[\"desire_jd_city_1\"]==df[\"city\"]\n",
    "    df[\"city_equal_desired_city_2\"] = df[\"desire_jd_city_2\"]==df[\"city\"]\n",
    "    df[\"city_equal_desired_city_3\"] = df[\"desire_jd_city_3\"]==df[\"city\"]\n",
    "    \n",
    "    df[\"work_years\"] = 2019-df[\"start_work_date\"].apply(lambda x : 2018 if x==\"-\" else int(x))\n",
    "    \n",
    "    \n",
    "    df[\"desire_min_salary\"] = df[\"desire_jd_salary_id\"].apply(lambda x: min_salary_dict[x])\n",
    "    df[\"desire_max_salary\"] = df[\"desire_jd_salary_id\"].apply(lambda x: max_salary_dict[x])\n",
    "    df[\"desire_salary_diff\"] = df[\"desire_max_salary\"]-df[\"desire_min_salary\"]\n",
    "    \n",
    "    df[\"min_years\"] = df[\"min_years\"].apply(lambda x: min_year_dict[x])\n",
    "    \n",
    "    df[\"work_years_statisfied\"] = df[\"work_years\"].astype(int) > df[\"min_years\"]\n",
    "    \n",
    "    df[\"salary_large_than_desire\"] = df[\"desire_min_salary\"] > df[\"min_salary\"]\n",
    "    \n",
    "    df[\"cur_salary_min\"] = df[\"cur_salary_id\"].apply(lambda x: min_salary_dict[int(x if str.isnumeric(x) else \"0\")])\n",
    "    df[\"cur_salary_max\"] = df[\"cur_salary_id\"].apply(lambda x: max_salary_dict[int(x if str.isnumeric(x) else \"0\")])\n",
    "    \n",
    "    df[\"salary_large_than_cur\"] = df[\"cur_salary_min\"] > df[\"min_salary\"]\n",
    "    \n",
    "    df[\"cur_degree_id\"] = df[\"cur_degree_id\"].fillna(\"na\").apply(lambda x:degree_dict[x.strip()])\n",
    "    \n",
    "    df[\"job_description_len\"] = df[\"job_description\"].apply(len)\n",
    "    \n",
    "    df[\"experience_num\"] = df[\"experience\"].apply(lambda x: len(str(x).split(\"|\")) if str(x) != \"nan\" else 0)\n",
    "    \n",
    "    df[\"min_edu_level\"] = df[\"min_edu_level\"].fillna(\"na\").apply(lambda x:degree_dict[x.strip()])\n",
    "    exp_in_desc_num = []\n",
    "    for idx, data in df.iterrows():\n",
    "        exp_in_desc_num.append(exp_in_desc(data[\"experience\"],data[\"job_description\"]))\n",
    "    df[\"exp_in_desc_num\"] = exp_in_desc_num\n",
    "    \n",
    "#     \"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "#          \"cur_degree_id\",\"city\",\"jd_sub_type\",\n",
    "#          \"max_salary\",\"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "#          \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"work_years_statisfied\"\n",
    "#  \"jd_sub_browsed_dicret\",\"jd_sub_delivered_dicret\",\"jd_sub_satisfied_dicret\"  \n",
    "    cross_feature_tuple = [(\"live_city_id\",\"city\"),(\"live_city_id\",\"desire_jd_city_1\"),(\"cur_industry_id\",\"jd_sub_type\"),\n",
    "                          (\"cur_jd_type\",\"jd_sub_type\"),(\"cur_salary_id\",\"cur_degree_id\"),(\"city\",\"jd_sub_type\"),\n",
    "                          (\"jd_sub_type\",\"min_salary\"),(\"jd_sub_type\",\"max_salary\"),(\"jd_sub_type\",\"is_travel\"),\n",
    "                          (\"min_years\",\"jd_sub_type\"),(\"jd_sub_type\",\"require_nums\"),\n",
    "                          ]\n",
    "    cross_feature_names = list(feature[0]+\"&\"+feature[1] for feature in cross_feature_tuple)\n",
    "    print(\"create cross features\",cross_feature_names)\n",
    "    for idx,(fa,fb) in enumerate(cross_feature_tuple):\n",
    "        df[cross_feature_names[idx]] = df[fa].astype(str)+df[fb].astype(str)\n",
    "    return cross_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create cross features ['live_city_id&city', 'live_city_id&desire_jd_city_1', 'cur_industry_id&jd_sub_type', 'cur_jd_type&jd_sub_type', 'cur_salary_id&cur_degree_id', 'city&jd_sub_type', 'jd_sub_type&min_salary', 'jd_sub_type&max_salary', 'jd_sub_type&is_travel', 'min_years&jd_sub_type', 'jd_sub_type&require_nums']\n",
      "create cross features ['live_city_id&city', 'live_city_id&desire_jd_city_1', 'cur_industry_id&jd_sub_type', 'cur_jd_type&jd_sub_type', 'cur_salary_id&cur_degree_id', 'city&jd_sub_type', 'jd_sub_type&min_salary', 'jd_sub_type&max_salary', 'jd_sub_type&is_travel', 'min_years&jd_sub_type', 'jd_sub_type&require_nums']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['live_city_id&city',\n",
       " 'live_city_id&desire_jd_city_1',\n",
       " 'cur_industry_id&jd_sub_type',\n",
       " 'cur_jd_type&jd_sub_type',\n",
       " 'cur_salary_id&cur_degree_id',\n",
       " 'city&jd_sub_type',\n",
       " 'jd_sub_type&min_salary',\n",
       " 'jd_sub_type&max_salary',\n",
       " 'jd_sub_type&is_travel',\n",
       " 'min_years&jd_sub_type',\n",
       " 'jd_sub_type&require_nums']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_feature_names = fe(train_big_table)\n",
    "fe(test_big_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_big_table = pd.concat([train_big_table,test_big_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm as tqdm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(target,*df_list):\n",
    "    result = []\n",
    "    cat_features = [\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "         \"cur_degree_id\",\"city\",\"jd_sub_type\",\"start_month\",\n",
    "         \"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "         \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"work_years_statisfied\"]+cross_feature_names\n",
    "    lbl_dict = {}\n",
    "    for f in cat_features:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(all_big_table[f].astype(str))\n",
    "        lbl_dict[f] = lbl\n",
    "    for df in df_list:\n",
    "        features = [\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "             \"cur_degree_id\",\"birthday\",\"city\",\"jd_sub_type\",\"require_nums\",\"jd_sub_statis_del_rate\",\"cur_jd_statis_del_rate\",\n",
    "                    \"start_month\",\"jd_title_statis_del_rate\",\n",
    "             \"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "             \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"exp_in_desc_num\",\n",
    "                   \"desire_min_salary\",\"desire_max_salary\",\"salary_large_than_desire\",\"cur_salary_min\",\n",
    "                   \"cur_salary_max\",\"salary_large_than_cur\",\"job_description_len\",\"experience_num\",\"work_years_statisfied\",\"work_years\",\"desire_jd_city_num\",\"desire_salary_diff\"]+cross_feature_names\n",
    "\n",
    "        x = df[features]\n",
    "        if target in df.columns:\n",
    "            y = df[target]\n",
    "        else:\n",
    "            y = None\n",
    "        for f in cat_features:\n",
    "            lbl = lbl_dict[f]\n",
    "            x[f] = lbl.transform(x[f].astype(str))\n",
    "        result.append((x,y))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(param=dict(n_estimators=1000,metric=\"map\",colsample_bytree=0.2,max_depth=7,importance_type=\"gain\",device=\"gpu\",gpu_platform_id=0,gpu_device_id=0)\n",
    "                   ,n_folds=5,target=\"mix_sat\"):\n",
    "    train_users = train_big_table[\"user_id\"].unique()\n",
    "    folds = KFold(n_folds,shuffle=True,random_state=42)\n",
    "    models = []\n",
    "    test_pred = np.zeros(test_big_table.shape[0])\n",
    "    scores = []\n",
    "    for idx,(train_idx,valid_idx) in enumerate(folds.split(train_users)):\n",
    "        t_user = train_users[train_idx]\n",
    "        v_user = train_users[valid_idx]\n",
    "        train_data = train_big_table[train_big_table[\"user_id\"].isin(t_user)]\n",
    "        valid_data = train_big_table[train_big_table[\"user_id\"].isin(v_user)]\n",
    "        train_group = train_data.groupby(\"user_id\",as_index=False).count()[\"mix_sat\"].values\n",
    "        valid_group = valid_data.groupby(\"user_id\",as_index=False).count()[\"mix_sat\"].values\n",
    "        test_group = test_big_table.groupby(\"user_id\",as_index=False).count()[\"jd_no\"].values\n",
    "        \n",
    "        \n",
    "        \n",
    "        jd_sub_action_series = train_data.groupby(['jd_sub_type'])['browsed'].count()\n",
    "        jd_sub_action =pd.DataFrame({'jd_sub_type':jd_sub_action_series.index, 'jd_sub_pos_cont':jd_sub_action_series.values})\n",
    "        jd_sub_action['jd_sub_statis_del_rate'] = train_data.groupby(['jd_sub_type'])['statis_del'].mean().values\n",
    "        train_data = pd.merge(train_data,jd_sub_action,how=\"left\",on=\"jd_sub_type\")\n",
    "        valid_data = pd.merge(valid_data,jd_sub_action,how=\"left\",on=\"jd_sub_type\")\n",
    "        valid_data.loc[valid_data['jd_sub_pos_cont'].isnull(),['jd_sub_statis_del_rate']] =train_data[train_data['jd_sub_type'].str.contains('小众')][['jd_sub_statis_del_rate']].values[0]\n",
    "        \n",
    "       \n",
    "        \n",
    "        cur_jd_action_series = train_data.groupby(['cur_jd_type'])['browsed'].count()\n",
    "        cur_jd_action =pd.DataFrame({'cur_jd_type':cur_jd_action_series.index, 'cur_jd_pos_cont':cur_jd_action_series.values})\n",
    "        cur_jd_action['cur_jd_statis_del_rate'] = train_data.groupby(['cur_jd_type'])['statis_del'].mean().values\n",
    "        train_data = pd.merge(train_data,cur_jd_action,how=\"left\",on=\"cur_jd_type\")\n",
    "        valid_data = pd.merge(valid_data,cur_jd_action,how=\"left\",on=\"cur_jd_type\")\n",
    "        valid_data.loc[valid_data['cur_jd_pos_cont'].isnull(),['cur_jd_statis_del_rate']]=train_data[train_data['cur_jd_type'].str.contains('其他')][['cur_jd_statis_del_rate']].values[0]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        desire_jd_industry_action_series = train_data.groupby(['desire_jd_type_id'])['browsed'].count()\n",
    "        desire_jd_industry_action =pd.DataFrame({'desire_jd_type_id':desire_jd_industry_action_series.index, 'desire_jd_industry_pos_cont':desire_jd_industry_action_series.values})\n",
    "        desire_jd_industry_action['desire_jd_industry_statis_del_rate'] = train_data.groupby(['desire_jd_type_id'])['statis_del'].mean().values\n",
    "        train_data = pd.merge(train_data,desire_jd_industry_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "        valid_data = pd.merge(valid_data,desire_jd_industry_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "        valid_data.loc[valid_data['desire_jd_industry_pos_cont'].isnull(),['desire_jd_industry_statis_del_rate']]=desire_jd_industry_action[desire_jd_industry_action['desire_jd_type_id'].str.contains('小众')][['desire_jd_industry_statis_del_rate']].values[0]\n",
    "\n",
    "\n",
    "     \n",
    "     \n",
    "        desire_jd_type_action_series = train_data.groupby(['desire_jd_type_id'])['browsed'].count()\n",
    "        desire_jd_type_action =pd.DataFrame({'desire_jd_type_id':desire_jd_type_action_series.index, 'desire_jd_type_pos_cont':desire_jd_type_action_series.values})\n",
    "        desire_jd_type_action['desire_jd_type_statis_del_rate'] = train_data.groupby(['desire_jd_type_id'])['statis_del'].mean().values\n",
    "        train_data = pd.merge(train_data,desire_jd_type_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "        valid_data = pd.merge(valid_data,desire_jd_type_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "        valid_data.loc[valid_data['desire_jd_type_pos_cont'].isnull(),['desire_jd_type_statis_del_rate']] =desire_jd_type_action[desire_jd_type_action['desire_jd_type_id'].str.contains('小众')][['desire_jd_type_statis_del_rate']].values[0]\n",
    "       \n",
    "        '''\n",
    "\n",
    "        \n",
    "\n",
    "        jd_title_series = train_data.groupby(['jd_title'])['browsed'].count()\n",
    "        jd_title_action =pd.DataFrame({'jd_title':jd_title_series.index, 'cur_jd_pos_cont':jd_title_series.values})\n",
    "        jd_title_action['jd_title_statis_del_rate'] = train_data.groupby(['jd_title'])['statis_del'].mean().values\n",
    "        train_data = pd.merge(train_data,jd_title_action,how=\"left\",on=\"jd_title\")\n",
    "        valid_data = pd.merge(valid_data,jd_title_action,how=\"left\",on=\"jd_title\")\n",
    "        valid_data.loc[valid_data['jd_title'].isnull(),['jd_title_statis_del_rate']]=jd_title_action[jd_title_action['jd_title'].str.contains('小众')][['jd_title_statis_del_rate']].values[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        result = feature_select(target,train_data,valid_data,test_big_table)\n",
    "        t_x,t_y = result[0]\n",
    "        v_x,v_y = result[1]\n",
    "        test_x,_ = result[2]\n",
    "        model = lgb.LGBMRanker(**param)\n",
    "        print(\"Fold\",idx,\"-\"*30)\n",
    "        model.fit(t_x,t_y,group=train_group,eval_set=[(t_x,t_y),(v_x,v_y)],eval_group=[train_group,valid_group],early_stopping_rounds=100,verbose=10,\n",
    "                  callbacks=[lgb.reset_parameter(learning_rate=lambda x: 0.03)]\n",
    "                 )\n",
    "        models.append(model)\n",
    "        test_pred += model.predict(test_x)/n_folds\n",
    "        scores.append(model.best_score_[\"valid_1\"][\"map@1\"])\n",
    "    print(\"mean score\",np.mean(scores))\n",
    "    return models,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506175, 68)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_big_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.263348\tvalid_1's map@1: 0.193548\n",
      "[20]\ttraining's map@1: 0.286986\tvalid_1's map@1: 0.201335\n",
      "[30]\ttraining's map@1: 0.289766\tvalid_1's map@1: 0.215795\n",
      "[40]\ttraining's map@1: 0.296719\tvalid_1's map@1: 0.211346\n",
      "[50]\ttraining's map@1: 0.300056\tvalid_1's map@1: 0.21802\n",
      "[60]\ttraining's map@1: 0.303949\tvalid_1's map@1: 0.221357\n",
      "[70]\ttraining's map@1: 0.314238\tvalid_1's map@1: 0.213571\n",
      "[80]\ttraining's map@1: 0.3198\tvalid_1's map@1: 0.209121\n",
      "[90]\ttraining's map@1: 0.322303\tvalid_1's map@1: 0.213571\n",
      "[100]\ttraining's map@1: 0.32842\tvalid_1's map@1: 0.21802\n",
      "[110]\ttraining's map@1: 0.333704\tvalid_1's map@1: 0.215795\n",
      "[120]\ttraining's map@1: 0.335929\tvalid_1's map@1: 0.214683\n",
      "[130]\ttraining's map@1: 0.338988\tvalid_1's map@1: 0.215795\n",
      "[140]\ttraining's map@1: 0.346774\tvalid_1's map@1: 0.219132\n",
      "[150]\ttraining's map@1: 0.348721\tvalid_1's map@1: 0.219132\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's map@1: 0.302558\tvalid_1's map@1: 0.223582\n",
      "Fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.258621\tvalid_1's map@1: 0.202447\n",
      "[20]\ttraining's map@1: 0.283927\tvalid_1's map@1: 0.215795\n",
      "[30]\ttraining's map@1: 0.292269\tvalid_1's map@1: 0.223582\n",
      "[40]\ttraining's map@1: 0.301168\tvalid_1's map@1: 0.220245\n",
      "[50]\ttraining's map@1: 0.309232\tvalid_1's map@1: 0.228031\n",
      "[60]\ttraining's map@1: 0.312848\tvalid_1's map@1: 0.219132\n",
      "[70]\ttraining's map@1: 0.317853\tvalid_1's map@1: 0.221357\n",
      "[80]\ttraining's map@1: 0.318409\tvalid_1's map@1: 0.213571\n",
      "[90]\ttraining's map@1: 0.325083\tvalid_1's map@1: 0.21802\n",
      "[100]\ttraining's map@1: 0.325362\tvalid_1's map@1: 0.215795\n",
      "[110]\ttraining's map@1: 0.332314\tvalid_1's map@1: 0.21802\n",
      "[120]\ttraining's map@1: 0.333704\tvalid_1's map@1: 0.223582\n",
      "[130]\ttraining's map@1: 0.335929\tvalid_1's map@1: 0.220245\n",
      "[140]\ttraining's map@1: 0.338154\tvalid_1's map@1: 0.216908\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's map@1: 0.306452\tvalid_1's map@1: 0.228031\n",
      "Fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.248053\tvalid_1's map@1: 0.205784\n",
      "[20]\ttraining's map@1: 0.26891\tvalid_1's map@1: 0.211346\n",
      "[30]\ttraining's map@1: 0.276974\tvalid_1's map@1: 0.222469\n",
      "[40]\ttraining's map@1: 0.278365\tvalid_1's map@1: 0.228031\n",
      "[50]\ttraining's map@1: 0.287542\tvalid_1's map@1: 0.226919\n",
      "[60]\ttraining's map@1: 0.291435\tvalid_1's map@1: 0.226919\n",
      "[70]\ttraining's map@1: 0.298665\tvalid_1's map@1: 0.235818\n",
      "[80]\ttraining's map@1: 0.298387\tvalid_1's map@1: 0.230256\n",
      "[90]\ttraining's map@1: 0.305061\tvalid_1's map@1: 0.233593\n",
      "[100]\ttraining's map@1: 0.310623\tvalid_1's map@1: 0.222469\n",
      "[110]\ttraining's map@1: 0.314516\tvalid_1's map@1: 0.229143\n",
      "[120]\ttraining's map@1: 0.317853\tvalid_1's map@1: 0.221357\n",
      "[130]\ttraining's map@1: 0.324249\tvalid_1's map@1: 0.220245\n",
      "[140]\ttraining's map@1: 0.328142\tvalid_1's map@1: 0.220245\n",
      "[150]\ttraining's map@1: 0.333426\tvalid_1's map@1: 0.221357\n",
      "[160]\ttraining's map@1: 0.337319\tvalid_1's map@1: 0.216908\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's map@1: 0.29644\tvalid_1's map@1: 0.238042\n",
      "Fold 3 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.253059\tvalid_1's map@1: 0.213571\n",
      "[20]\ttraining's map@1: 0.273637\tvalid_1's map@1: 0.197998\n",
      "[30]\ttraining's map@1: 0.281146\tvalid_1's map@1: 0.21802\n",
      "[40]\ttraining's map@1: 0.29366\tvalid_1's map@1: 0.223582\n",
      "[50]\ttraining's map@1: 0.307842\tvalid_1's map@1: 0.222469\n",
      "[60]\ttraining's map@1: 0.310901\tvalid_1's map@1: 0.219132\n",
      "[70]\ttraining's map@1: 0.316741\tvalid_1's map@1: 0.228031\n",
      "[80]\ttraining's map@1: 0.323415\tvalid_1's map@1: 0.224694\n",
      "[90]\ttraining's map@1: 0.331201\tvalid_1's map@1: 0.229143\n",
      "[100]\ttraining's map@1: 0.335373\tvalid_1's map@1: 0.223582\n",
      "[110]\ttraining's map@1: 0.336763\tvalid_1's map@1: 0.219132\n",
      "[120]\ttraining's map@1: 0.341769\tvalid_1's map@1: 0.212458\n",
      "[130]\ttraining's map@1: 0.342881\tvalid_1's map@1: 0.215795\n",
      "[140]\ttraining's map@1: 0.345384\tvalid_1's map@1: 0.215795\n",
      "[150]\ttraining's map@1: 0.347608\tvalid_1's map@1: 0.216908\n",
      "[160]\ttraining's map@1: 0.352058\tvalid_1's map@1: 0.216908\n",
      "[170]\ttraining's map@1: 0.353448\tvalid_1's map@1: 0.219132\n",
      "[180]\ttraining's map@1: 0.356785\tvalid_1's map@1: 0.216908\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's map@1: 0.32703\tvalid_1's map@1: 0.233593\n",
      "Fold 4 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.258065\tvalid_1's map@1: 0.195773\n",
      "[20]\ttraining's map@1: 0.271969\tvalid_1's map@1: 0.210234\n",
      "[30]\ttraining's map@1: 0.277253\tvalid_1's map@1: 0.212458\n",
      "[40]\ttraining's map@1: 0.283092\tvalid_1's map@1: 0.210234\n",
      "[50]\ttraining's map@1: 0.288654\tvalid_1's map@1: 0.209121\n",
      "[60]\ttraining's map@1: 0.296162\tvalid_1's map@1: 0.221357\n",
      "[70]\ttraining's map@1: 0.299499\tvalid_1's map@1: 0.214683\n",
      "[80]\ttraining's map@1: 0.303115\tvalid_1's map@1: 0.211346\n",
      "[90]\ttraining's map@1: 0.304783\tvalid_1's map@1: 0.212458\n",
      "[100]\ttraining's map@1: 0.307008\tvalid_1's map@1: 0.211346\n",
      "[110]\ttraining's map@1: 0.312013\tvalid_1's map@1: 0.215795\n",
      "[120]\ttraining's map@1: 0.313404\tvalid_1's map@1: 0.212458\n",
      "[130]\ttraining's map@1: 0.319522\tvalid_1's map@1: 0.214683\n",
      "[140]\ttraining's map@1: 0.324527\tvalid_1's map@1: 0.214683\n",
      "[150]\ttraining's map@1: 0.331201\tvalid_1's map@1: 0.216908\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's map@1: 0.294494\tvalid_1's map@1: 0.223582\n",
      "mean score 0.22936596218020022\n"
     ]
    }
   ],
   "source": [
    "models,pred = cross_validate(target=\"mix_sat\",param=dict(n_estimators=1000,metric=\"map\",subsample=0.6,min_split_gain=10,colsample_bytree=0.6,max_depth=7,importance_type=\"gain\",device=\"gpu\",gpu_platform_id=0,gpu_device_id=0),n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-bcbe6d77625b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                    \"cur_salary_max\",\"salary_large_than_cur\",\"job_description_len\",\"experience_num\",\"work_years_statisfied\",\"work_years\",\"desire_jd_city_num\",\"desire_salary_diff\"]+cross_feature_names\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mfold_importance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"importance\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mfold_importance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold_importance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3630\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_importance = pd.DataFrame()\n",
    "for idx,model in enumerate(models):\n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"feature\"] = [\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "             \"cur_degree_id\",\"birthday\",\"city\",\"jd_sub_type\",\"require_nums\",\"jd_sub_statis_del_rate\",\"cur_jd_statis_del_rate\",\"desire_jd_industry_statis_del_rate\",\n",
    "                    \"start_month\",\"jd_title_statis_del_rate\",\n",
    "             \"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "             \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"exp_in_desc_num\",\n",
    "                   \"desire_min_salary\",\"desire_max_salary\",\"salary_large_than_desire\",\"cur_salary_min\",\n",
    "                   \"cur_salary_max\",\"salary_large_than_cur\",\"job_description_len\",\"experience_num\",\"work_years_statisfied\",\"work_years\",\"desire_jd_city_num\",\"desire_salary_diff\"]+cross_feature_names\n",
    "\n",
    "    fold_importance[\"importance\"] = model.feature_importances_\n",
    "    fold_importance[\"fold\"] = idx\n",
    "    feature_importance = pd.concat([feature_importance,fold_importance])\n",
    "plt.figure(figsize=(16, 12));\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance.sort_values(by=\"importance\", ascending=False));\n",
    "plt.title('mix_satsatisfied LGB Features (avg over folds)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_table_tmp = pd.merge(train_big_table,jd_sub_action,how=\"left\",on=\"jd_sub_type\")\n",
    "train_big_table_tmp = pd.merge(train_big_table_tmp,cur_jd_action,how=\"left\",on=\"cur_jd_type\")\n",
    "#train_big_table_tmp = pd.merge(train_big_table_tmp,desire_jd_type_action,how=\"left\",on=\"desire_jd_type_id\")\n",
    "train_big_table_tmp = pd.merge(train_big_table_tmp,jd_title_action,how=\"left\",on=\"jd_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features with a correlation magnitude greater than 0.80.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop_feature</th>\n",
       "      <th>corr_feature</th>\n",
       "      <th>corr_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desire_max_salary</td>\n",
       "      <td>desire_min_salary</td>\n",
       "      <td>0.860420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cur_salary_max</td>\n",
       "      <td>cur_salary_min</td>\n",
       "      <td>0.868241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work_years</td>\n",
       "      <td>birthday</td>\n",
       "      <td>0.925685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desire_jd_city_num</td>\n",
       "      <td>desire_jd_city_1</td>\n",
       "      <td>0.955741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desire_salary_diff</td>\n",
       "      <td>desire_max_salary</td>\n",
       "      <td>0.938315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         drop_feature       corr_feature  corr_value\n",
       "0   desire_max_salary  desire_min_salary    0.860420\n",
       "1      cur_salary_max     cur_salary_min    0.868241\n",
       "2          work_years           birthday    0.925685\n",
       "3  desire_jd_city_num   desire_jd_city_1    0.955741\n",
       "4  desire_salary_diff  desire_max_salary    0.938315"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_selector import FeatureSelector\n",
    "feature_list =[\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "             \"cur_degree_id\",\"birthday\",\"city\",\"jd_sub_type\",\"require_nums\",\"jd_sub_statis_del_rate\",\"cur_jd_statis_del_rate\",\n",
    "                    \"start_month\",\"jd_title_statis_del_rate\",\n",
    "             \"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "             \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"exp_in_desc_num\",\n",
    "                   \"desire_min_salary\",\"desire_max_salary\",\"salary_large_than_desire\",\"cur_salary_min\",\n",
    "                   \"cur_salary_max\",\"salary_large_than_cur\",\"job_description_len\",\"experience_num\",\"work_years_statisfied\",\"work_years\",\"desire_jd_city_num\",\"desire_salary_diff\"]+cross_feature_names\n",
    "\n",
    "\n",
    "\n",
    "train_fr =train_big_table_tmp[feature_list]\n",
    "fs = FeatureSelector(data = train_fr, labels = train_big_table['mix_sat'])\n",
    "fs.identify_collinear(correlation_threshold=0.8)\n",
    "fs.record_collinear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>jd_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167827d429af352a93b28666c33ed0fd</td>\n",
       "      <td>6855780caa3e8b4c6c65adfacdda5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167827d429af352a93b28666c33ed0fd</td>\n",
       "      <td>20603e8eec8f4fbab757ad70e86fdec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167827d429af352a93b28666c33ed0fd</td>\n",
       "      <td>b612c4ec69756fe4944071cb0525ef8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167827d429af352a93b28666c33ed0fd</td>\n",
       "      <td>0558a2371bbfa13eb9295f8011eeb997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167827d429af352a93b28666c33ed0fd</td>\n",
       "      <td>fde5a7db457d1123f56be0e295576c0c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                             jd_no\n",
       "0  167827d429af352a93b28666c33ed0fd  6855780caa3e8b4c6c65adfacdda5282\n",
       "1  167827d429af352a93b28666c33ed0fd  20603e8eec8f4fbab757ad70e86fdec2\n",
       "2  167827d429af352a93b28666c33ed0fd  b612c4ec69756fe4944071cb0525ef8d\n",
       "3  167827d429af352a93b28666c33ed0fd  0558a2371bbfa13eb9295f8011eeb997\n",
       "4  167827d429af352a93b28666c33ed0fd  fde5a7db457d1123f56be0e295576c0c"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_action = pd.read_csv(\"data/zhaopin_round1_user_exposure_B_20190819\",delim_whitespace=True)\n",
    "test_action.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "submit = test_big_table[[\"user_id\",\"jd_no\"]]\n",
    "submit[\"score\"] = pred\n",
    "submit = submit.reset_index(drop=True)\n",
    "result = pd.merge(test_action,submit,how=\"left\",on=[\"user_id\",\"jd_no\"])\n",
    "result.fillna(-100,inplace=True)\n",
    "result = result.groupby(\"user_id\",as_index=False).apply(lambda x:x.sort_values(\"score\",ascending=False))\n",
    "result[[\"user_id\",\"jd_no\",\"score\"]].to_csv(\"submission2_x.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "submit = test_big_table[[\"user_id\",\"jd_no\"]]\n",
    "submit[\"score\"] = pred\n",
    "submit = submit.reset_index(drop=True)\n",
    "result = pd.merge(test_action,submit,how=\"left\",on=[\"user_id\",\"jd_no\"])\n",
    "result.fillna(-100,inplace=True)\n",
    "result = result.groupby(\"user_id\",as_index=False).apply(lambda x:x.sort_values(\"score\",ascending=False))\n",
    "# 需要对结果进行去重\n",
    "result[[\"user_id\",\"jd_no\",\"score\"]].drop_duplicates().to_csv(\"submission2_x.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29674, 3)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[[\"user_id\",\"jd_no\",\"score\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work_years_statisfied=1\n",
    "#is_edu_ok？ 1\n",
    "#year&is_city_eq "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
